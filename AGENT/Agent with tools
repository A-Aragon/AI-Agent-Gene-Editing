import json
import os
import re
import requests
from dotenv import load_dotenv
from typing import Annotated, TypedDict
from langchain.chat_models import init_chat_model
from langchain_core.messages import ToolMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_tavily import TavilySearch

# Load environment variables
load_dotenv()
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if TAVILY_API_KEY is None:
    raise ValueError("TAVILY_API_KEY environment variable not set.")
if OPENAI_API_KEY is None:
    raise ValueError("OPENAI_API_KEY environment variable not set.")

# Define the Elixir Forecast tool
@tool
def get_forecast_predictions(target: str, pam_position: int) -> dict:
    """Retrieve predictions from the Elixir Forecast API for a CRISPR sequence."""
    url = "https://elixir.ut.ee/forecast/api/predict"
    payload = {"target": target, "pam_position": pam_position}
    headers = {"Content-Type": "application/json"}

    response = requests.post(url, json=payload, headers=headers)
    if response.status_code == 200:
        return response.json()
    else:
        return {"error": f"Status code {response.status_code}: {response.text}"}

# Define the WGE CRISPR guide tool
@tool
def get_crisprs_by_exon(species: str, exon_ids: list[str]) -> dict:
    """Retrieve CRISPR guides for a species and list of exon IDs using the WGE API."""
    url = "https://wge.stemcell.sanger.ac.uk/api/crispr_search"
    params = {"species": species}
    for exon_id in exon_ids:
        params.setdefault("exon_id[]", []).append(exon_id)

    response = requests.get(url, params=params)
    if response.status_code == 200:
        raw_data = response.json()
        processed = {}
        for exon_id, guides in raw_data.items():
            processed[exon_id] = []
            for guide in guides:
                species_name = (
                    "Mouse" if guide.get("species_id") == 2
                    else "Human" if guide.get("species_id") == 4
                    else guide.get("species_id")
                )
                processed[exon_id].append({
                    "id": guide.get("id"),
                    "chr_name": guide.get("chr_name"),
                    "chr_start": guide.get("chr_start"),
                    "chr_end": guide.get("chr_end"),
                    "seq": guide.get("seq"),
                    "pam_right": guide.get("pam_right"),
                    "ensembl_exon_id": guide.get("ensembl_exon_id"),
                    "off_target_summary": guide.get("off_target_summary"),
                    "exonic": guide.get("exonic"),
                    "species": species_name
                })
        return processed
    else:
        return {"error": f"Status code {response.status_code}: {response.text}"}

# Set up the TavilySearch tool (for web search)
tavily_tool = TavilySearch(max_results=2)

# Combine all tools
tools = [get_forecast_predictions, get_crisprs_by_exon, tavily_tool]

# Define State
class State(TypedDict):
    messages: Annotated[list, add_messages]

# Initialize LangGraph state graph
graph_builder = StateGraph(State)

# Initialize the chat model
llm = init_chat_model("openai:gpt-4")

# Bind tools to the LLM
llm_with_tools = llm.bind_tools(tools)

# Define chatbot function to interact with the user
def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}

# Add chatbot node to the graph
graph_builder.add_node("chatbot", chatbot)

# Define a BasicToolNode that runs the tools requested in the last AIMessage
class BasicToolNode:
    """A node that runs the tools requested in the last AIMessage."""
    def __init__(self, tools: list) -> None:
        self.tools_by_name = {tool.name: tool for tool in tools}

    def __call__(self, inputs: dict):
        if messages := inputs.get("messages", []):
            message = messages[-1]
        else:
            raise ValueError("No message found in input")
        outputs = []
        for tool_call in message.tool_calls:
            tool_result = self.tools_by_name[tool_call["name"]].invoke(tool_call["args"])
            outputs.append(
                ToolMessage(
                    content=json.dumps(tool_result),
                    name=tool_call["name"],
                    tool_call_id=tool_call["id"],
                )
            )
        return {"messages": outputs}

# Add the BasicToolNode to the graph
tool_node = BasicToolNode(tools=tools)
graph_builder.add_node("tools", tool_node)

# Define the router function for conditional edges
def route_tools(state: State):
    """Route to the ToolNode if the last message has tool calls, otherwise end."""
    if isinstance(state, list):
        ai_message = state[-1]
    elif messages := state.get("messages", []):
        ai_message = messages[-1]
    else:
        raise ValueError(f"No messages found in input state to tool_edge: {state}")
    if hasattr(ai_message, "tool_calls") and len(ai_message.tool_calls) > 0:
        return "tools"
    return END

# Add the conditional edges
graph_builder.add_conditional_edges(
    "chatbot",
    route_tools,
    {"tools": "tools", END: END},
)

# Add the edge from tools back to the chatbot
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")

# Compile the graph
graph = graph_builder.compile()

# Function to process user input and trigger the graph
def stream_graph_updates(user_input):
    # User sends a message to the agent
    state = {"messages": [{"role": "user", "content": user_input}]}

    # Run the graph
    result = graph.invoke(state)
    print(f"Assistant: {result['messages'][-1].content}")  # Access content using .content

# Start the chatbot loop
if __name__ == "__main__":
    while True:
        try:
            user_input = input("User: ")
            if user_input.lower() in ["quit", "exit", "q"]:
                print("Goodbye!")
                break

            # Send user input to the agent
            stream_graph_updates(user_input)

        except KeyboardInterrupt:
            print("\nGoodbye!")
            break

