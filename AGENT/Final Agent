# crispr_chatbot.py
# -----------------------------------------------------------
# LangGraph CRISPR assistant with grouped external tools
# (forecast_basic, forecast_repair, and WGE CRISPR Search removed)
# -----------------------------------------------------------

import json
import os
import time
import urllib.parse
from typing import Annotated, Optional, TypedDict

import requests
from dotenv import load_dotenv
from langchain.chat_models import init_chat_model
from langchain.callbacks import get_openai_callback
from langchain.schema import HumanMessage
from langchain_core.messages import ToolMessage
from langchain_core.tools import tool
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, START, StateGraph
from langgraph.graph.message import add_messages
from langchain_tavily import TavilySearch
from typing import Dict
from langchain_core.tools import tool
from typing import Dict, List
from langchain_core.tools import tool
import requests
import re

# Load environment variables
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
if not OPENAI_API_KEY or not TAVILY_API_KEY:
    raise EnvironmentError("OPENAI_API_KEY / TAVILY_API_KEY missing in environment.")

# ----------------------------
# Define Tools (remaining only)
# ----------------------------

@tool
def get_forecast_predictions_tool(target: str, pam_position: int) -> Dict:
    """
    Fetch the top-10 CRISPR edit outcome predictions from Elixir-Forecast
    and return them in a format that explicitly exposes the mutation outcomes.

    Parameters
    ----------
    target : str
        Full CRISPR target sequence (protospacer + PAM)
    pam_position : int
        0-based index of the PAM within `target`

    Returns
    -------
    Dict
        {
            "results":               [<mutation_outcome>, ...],  # just strings
            "top_10_predictions":    [<full-prediction-dict>, ...],
            "summary":               "<markdown summary ready to print>"
        }
    """
    url = "https://elixir.ut.ee/forecast/api/predict"
    payload = {"target": target, "pam_position": pam_position}
    headers = {"Content-Type": "application/json"}

    response = requests.post(url, json=payload, headers=headers)
    if response.status_code != 200:
        return {
            "error": f"Forecast API error: {response.status_code}",
            "detail": response.text
        }

    data = response.json()
    rows = data.get("data", {}).get("data", "").split("\n")[1:]  # skip header

    predictions: List[Dict] = []
    for row in rows:
        cols = row.split(",")
        if len(cols) < 4:
            continue

        mutation_outcome = cols[1]
        inserted_sequence = cols[2] or "No insertada"
        try:
            prediction_score = float(cols[3])
        except ValueError:
            continue

        # classify by outcome code
        if mutation_outcome.startswith("I1"):
            mutation_type = "Ins (1 bp)"
        elif mutation_outcome.startswith("I"):
            mutation_type = "Inserción (>1 bp)"
        elif mutation_outcome.startswith("D"):
            m = re.match(r"D(\d+)", mutation_outcome)
            size = int(m.group(1)) if m else 0
            if size <= 2:
                mutation_type = "Deleción (1-2 bp)"
            elif size <= 9:
                mutation_type = "Deleción (3-9 bp)"
            else:
                mutation_type = "Deleción (>9 bp)"
        else:
            mutation_type = "Otro tipo"

        predictions.append({
            "mutation_outcome": mutation_outcome,
            "mutation_type": mutation_type,
            "inserted_sequence": inserted_sequence,
            "prediction_score": prediction_score
        })

    # rank & keep top-10
    top10 = sorted(predictions, key=lambda x: x["prediction_score"], reverse=True)[:10]

    # plain list of mutation outcomes, in ranked order
    results = [p["mutation_outcome"] for p in top10]

    # human-friendly markdown summary
    summary_lines = []
    for i, p in enumerate(top10, 1):
        seq_text = (
            "No sequence inserted"
            if p["inserted_sequence"] == "No insertada"
            else f'Inserted sequence "{p["inserted_sequence"]}"'
        )
        summary_lines.append(
            f"{i}. **{p['mutation_type']}** (`{p['mutation_outcome']}`): "
            f"{seq_text} (score {p['prediction_score']:.2f})"
        )
    summary = "\n".join(summary_lines)

    return {
        "results": results,                 # ← just the mutation codes
        "top_10_predictions": top10,        # ← full detail for power-users
        "summary": summary                  # ← ready-to-print markdown
    }

@tool
def get_forecast_repair_predictions_tool(
    target: str,
    pam_position: int,
    context: str,
    retries: int = 2,
    delay: int = 1
) -> dict:
    """
    Calls the Elixir Forecast-Repair API for a given target, PAM position, and repair context.
    Repeats up to `retries` times, sleeping `delay` seconds between attempts.
    Returns parsed JSON on success, or an error dict on failure.

    Arguments:
      - target: Full CRISPR sequence (20nt + PAM, e.g. "ACGTTGAC...GGG")
      - pam_position: integer index of the PAM (e.g. 17 if using zero-based)
      - context: one of the valid repair contexts (e.g. "Lig3", "NHEJ", "control", etc.)
      - retries: how many times to retry on failure (default 2)
      - delay: seconds to wait between retries (default 1)
    """
    url = "https://elixir.ut.ee/forecast-repair/api/predict"
    payload = {"target": target, "pam_position": pam_position, "context": context}
    headers = {"Content-Type": "application/json"}

    for attempt in range(1, retries + 1):
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=30)
            if response.status_code == 200:
                data = response.json()
                # Parse the CSV-like body into a list of dicts:
                forecasts = []
                rows = data.get("data", "").split("\n")[1:]  # skip header row
                for row in rows:
                    cols = row.split(",")
                    if len(cols) >= 4:
                        mutation_outcome = cols[1]
                        inserted_seq = cols[2] or "No insertada"
                        pred_score = float(cols[3])
                        # classify mutation type
                        if mutation_outcome.startswith("I1"):
                            mut_type = "Ins (1bp)"
                        elif mutation_outcome.startswith("I"):
                            mut_type = "Inserción (>1 bp)"
                        elif mutation_outcome.startswith("D"):
                            m = re.match(r"D(\d+)", mutation_outcome)
                            size = int(m.group(1)) if m else 0
                            if size <= 2:
                                mut_type = "Deleción (1-2 bp)"
                            elif 3 <= size <= 9:
                                mut_type = "Deleción (3-9 bp)"
                            else:
                                mut_type = "Deleción (>9 bp)"
                        else:
                            mut_type = "Otro tipo"

                        forecasts.append({
                            "mutation_outcome": mutation_outcome,
                            "mutation_type": mut_type,
                            "inserted_sequence": inserted_seq,
                            "prediction_score": pred_score
                        })
                # Sort and return top 10
                top10 = sorted(forecasts, key=lambda x: x["prediction_score"], reverse=True)[:10]
                return {"top_10_repair_predictions": top10}
            else:
                print(f"[ERROR] Attempt {attempt}: context={context} | "
                      f"Status {response.status_code} {response.text}")
        except requests.exceptions.RequestException as e:
            print(f"[ERROR] Attempt {attempt}: connection error for {context}: {e}")

        if attempt < retries:
            time.sleep(delay)

    return {"error": f"No valid response after {retries} attempts for context='{context}'."}


@tool
def crispr_toolkit(
    action: str,
    species: str,
    exon_ids: Optional[list[str]] = None,
    seq: Optional[str] = None,
    pam_right: Optional[bool] = None,
    crispr_id: Optional[str] = None,
) -> dict:
    """
    Combined WGE utilities.
    ────────────────────────────────────────────
    action = "guides_by_exon"
        ▸ requires  exon_ids (list[str])
    action = "off_targets_by_seq"
        ▸ requires  seq (20 bp)  · pam_right (bool)
    action = "off_targets_by_id"
        ▸ requires  crispr_id (str)
    species = "grch38" | "mouse" | …
    """
    base = "https://wge.stemcell.sanger.ac.uk/api"

    # Normalize species name to match WGE expected values
    species_map = {
        "human": "Grch38",
        "mouse": "Mouse",
        "grch38": "Grch38",  # optional redundancy
    }
    species = species_map.get(species.lower(), species)

    try:
        if action == "guides_by_exon":
            if not exon_ids:
                return {"error": "Missing exon_ids list."}
            r = requests.get(
                f"{base}/crispr_search",
                params={"species": species, "exon_id[]": exon_ids},
                timeout=30,
            )
            r.raise_for_status()
            return r.json()

        if action == "off_targets_by_seq":
            if seq is None or pam_right is None:
                return {"error": "Requires seq and pam_right."}
            r = requests.get(
                f"{base}/off_targets_by_seq",
                params={"species": species, "seq": seq, "pam_right": str(pam_right).lower()},
                timeout=30,
            )
            r.raise_for_status()
            return r.json()

        if action == "off_targets_by_id":
            if not crispr_id:
                return {"error": "Missing crispr_id."}
            r = requests.post(
                f"{base}/crispr_off_targets",
                data={
                    "species": species,
                    "id": crispr_id,
                    "with_detail": 1,
                },
                headers={
                    "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
                    "X-Requested-With": "XMLHttpRequest",
                },
                timeout=30,
            )
            r.raise_for_status()
            return r.json()

        return {"error": f"Unknown action '{action}'."}
    except Exception as exc:
        return {"error": str(exc)}




@tool
def ncbi_list_databases_tool() -> Dict:
    """
    Obtiene la lista de bases de datos disponibles en NCBI (EInfo).
    Retorna:
      {
        "databases": [<lista de strings>]
      }
    O bien {"error": "..."} en caso de fallo.
    """
    url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/einfo.fcgi?retmode=json"
    try:
        resp = requests.get(url, timeout=20)
        resp.raise_for_status()
        data = resp.json()
        dblist = data.get("einforesult", {}).get("dblist", None)
        if dblist is None:
            return {"error": "No se encontró 'dblist' en la respuesta de EInfo."}
        return {"databases": dblist}
    except (requests.exceptions.RequestException, json.JSONDecodeError) as e:
        return {"error": f"EInfo error: {e}"}


@tool
def ncbi_esearch_tool(
    db: str,
    term: str,
    retmax: Optional[int] = 20,
    retstart: Optional[int] = 0,
    usehistory: Optional[str] = "y",
    mindate: Optional[str] = None,
    maxdate: Optional[str] = None,
    datetype: Optional[str] = None,
    reldate: Optional[int] = None,
    sort: Optional[str] = None
) -> Dict:
    """
    ESearch en NCBI Entrez:
      - db: base de datos (e.g. "pubmed")
      - term: término de búsqueda (e.g. "CRISPR AND cancer")
      - retmax: máximo de resultados (default 20)
      - retstart: índice inicial para paginación (default 0)
      - usehistory: "y" o "n" (default "y")
      - mindate, maxdate: para filtrar rango de fecha (formato YYYY/MM/DD o MM/YYYY o YYYY)
      - datetype: uno de ["pdat","edat","mdat","rdat"]
      - reldate: número de días relativos
      - sort: orden (depende de la db; ej. "relevance", "pub+date", etc.)
    Retorna:
      {
        "esearchresult": { … JSON bruto de ESearch … }
      }
    O bien {"error": "..."} en caso de fallo.
    """
    base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
    params = {
        "db": db,
        "term": term,
        "retmode": "json",
        "retmax": retmax,
        "retstart": retstart,
        "usehistory": usehistory,
        "mindate": mindate,
        "maxdate": maxdate,
        "datetype": datetype,
        "reldate": reldate,
        "sort": sort
    }
    # Quitar None
    clean_params = {k: v for k, v in params.items() if v is not None}
    full_url = f"{base_url}?{urllib.parse.urlencode(clean_params)}"
    try:
        resp = requests.get(full_url, timeout=20)
        resp.raise_for_status()
        data = resp.json()
        if "esearchresult" not in data:
            return {"error": "No se encontró 'esearchresult' en la respuesta de ESearch."}
        return {"esearchresult": data["esearchresult"]}
    except (requests.exceptions.RequestException, json.JSONDecodeError) as e:
        return {"error": f"ESearch error: {e}"}


@tool
def ncbi_esummary_tool(
    db: str,
    ids: List[str],
    retmode: Optional[str] = "json"
) -> Dict:
    """
    ESummary en NCBI Entrez:
      - db: base de datos (e.g. "pubmed")
      - ids: lista de UIDs como strings (e.g. ["12345","67890"])
      - retmode: (default "json")
    Retorna:
      {
        "esummaryresult": { … JSON bruto de ESummary … }
      }
    O bien {"error": "..."} en caso de fallo.
    """
    base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi"
    params = {
        "db": db,
        "id": ",".join(ids),
        "retmode": retmode
    }
    clean_params = {k: v for k, v in params.items() if v is not None}
    full_url = f"{base_url}?{urllib.parse.urlencode(clean_params)}"
    try:
        resp = requests.get(full_url, timeout=20)
        resp.raise_for_status()
        data = resp.json()
        # Devolver bajo llave "esummaryresult" para distinguirlo
        return {"esummaryresult": data}
    except (requests.exceptions.RequestException, json.JSONDecodeError) as e:
        return {"error": f"ESummary error: {e}"}

# Tavily Search Tool (unchanged)
tavily_tool = TavilySearch(max_results=2)

# Tool List (only the two remaining tools)
tools = [crispr_toolkit, get_forecast_predictions_tool, ncbi_list_databases_tool, ncbi_esearch_tool, ncbi_esummary_tool, get_forecast_repair_predictions_tool, tavily_tool]

# ----------------------------
# State Schema
# ----------------------------
class State(TypedDict):
    messages: Annotated[list, add_messages]

# ----------------------------
# Initialize Chat Model and Bind Tools
# ----------------------------
llm = init_chat_model("openai:gpt-4o-2024-08-06")
llm_with_tools = llm.bind_tools(tools)

# In-Memory Checkpoint (Memory)
memory = MemorySaver()

# LangGraph Construction
graph_builder = StateGraph(State)

# ----------------------------
# Chatbot Node
# ----------------------------
def chatbot(state: State):
    start_time = time.time()
    with get_openai_callback() as cb:
        result = llm_with_tools.invoke(state["messages"])
        cost_info = {
            "input_tokens": cb.prompt_tokens,
            "output_tokens": cb.completion_tokens,
            "total_tokens": cb.total_tokens,
            "input_cost": (cb.prompt_tokens / 1_000_000) * 2.50,
            "output_cost": (cb.completion_tokens / 1_000_000) * 10.00,
            "total_cost": (cb.prompt_tokens / 1_000_000) * 2.50 + (cb.completion_tokens / 1_000_000) * 10.00,
        }
    end_time = time.time()
    duration = end_time - start_time
    print(f"Node 'chatbot' completed in {duration:.4f} seconds.")
    print(
        f"Node 'chatbot' cost: Input ${cost_info['input_cost']:.6f}, "
        f"Output ${cost_info['output_cost']:.6f}, "
        f"Total ${cost_info['total_cost']:.6f} ({cost_info['total_tokens']} tokens)."
    )
    return {"messages": [result], "cost": cost_info}

graph_builder.add_node("chatbot", chatbot)

# ----------------------------
# Tool-Execution Node
# ----------------------------
class BasicToolNode:
    def __init__(self, tools: list) -> None:
        self.tools_by_name = {tool.name: tool for tool in tools}
        self.attempted_tool_calls = set()

    def __call__(self, inputs: dict):
        start_time = time.time()
        messages = inputs.get("messages", [])
        if not messages:
            raise ValueError("No message found in input")

        message = messages[-1]
        outputs = []

        for tool_call in message.tool_calls:
            tool_name = tool_call["name"]
            tool_args = tool_call["args"]

            # Create a unique identifier for the tool call
            tool_call_id = (tool_name, json.dumps(tool_args, sort_keys=True))

            if tool_call_id in self.attempted_tool_calls:
                print(f"⚠️ Skipping repeated tool call: {tool_name}")
                continue

            self.attempted_tool_calls.add(tool_call_id)

            print(f"\n🔧 Calling tool: {tool_name}")
            print(f"📦 Arguments: {json.dumps(tool_args, indent=2)}")

            tool_start_time = time.time()
            try:
                result = self.tools_by_name[tool_name].invoke(tool_args)
                tool_end_time = time.time()
                duration = tool_end_time - tool_start_time
                print(f"✅ Tool '{tool_name}' executed in {duration:.4f} seconds.")

                if isinstance(result, dict) and "error" in result:
                    print(f"❌ Tool returned error: {result['error']}")
                elif not result:
                    print(f"⚠️ Tool returned empty result.")
                else:
                    snippet = json.dumps(result, indent=2)
                    if len(snippet) > 1000:
                        snippet = snippet[:1000] + "... [truncated]"
                    print(f"📤 Tool result: {snippet}")
            except Exception as e:
                print(f"🔥 Exception in tool '{tool_name}': {e}")
                result = {"error": str(e)}

            outputs.append(
                ToolMessage(
                    content=json.dumps(result),
                    name=tool_name,
                    tool_call_id=tool_call["id"],
                )
            )

        end_time = time.time()
        print(f"🔄 Node 'tools' total time: {end_time - start_time:.4f} seconds.")
        return {"messages": outputs}

tool_node = BasicToolNode(tools=tools)
graph_builder.add_node("tools", tool_node)

# ----------------------------
# Router for Conditional Tool Execution
# ----------------------------
def route_tools(state: State):
    messages = state.get("messages", [])
    ai_message = messages[-1] if messages else None
    if hasattr(ai_message, "tool_calls") and ai_message.tool_calls:
        return "tools"
    return END

# Define Graph Edges
graph_builder.add_conditional_edges("chatbot", route_tools, {"tools": "tools", END: END})
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")

# Compile Graph with Memory
graph = graph_builder.compile(checkpointer=memory)

# ----------------------------
# Run Chatbot in CLI Loop
# ----------------------------
def stream_graph_updates(user_input: str):
    state = {"messages": [{"role": "user", "content": user_input}]}

    start_time = time.time()
    with get_openai_callback() as cb:
        result = graph.invoke(state, config={"configurable": {"thread_id": "1"}})
    end_time = time.time()

    # Calculate the cost at your rate (2.50 $ prompt, 10 $ completion per million)
    coste_turno = (cb.prompt_tokens / 1_000_000) * 2.50 + \
                  (cb.completion_tokens / 1_000_000) * 10.00

    print(f"\n🤖 Assistant: {result['messages'][-1].content}")
    print(f"Total turn time: {end_time - start_time:.4f} seconds.")
    print(f"Total turn cost: ${coste_turno:.6f}")

if __name__ == "__main__":
    print("🔬 CRISPR Chatbot with Tools and Memory\nType 'quit' to exit.")
    while True:
        try:
            user_input = input("🧑 User: ")
            if user_input.lower() in {"quit", "exit", "q"}:
                print("👋 Goodbye!")
                break
            stream_graph_updates(user_input)
        except KeyboardInterrupt:
            print("\n👋 Goodbye!")
            break
